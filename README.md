# ğŸ“š RAG Document Chatbot  
A Retrieval-Augmented Generation (RAG) chatbot using **Hugging Face**, **FAISS**, and **Gradio** to answer questions from your own documents.

![Python](https://img.shields.io/badge/Python-3.10+-blue?style=for-the-badge)
![Transformers](https://img.shields.io/badge/HuggingFace-Transformers-orange?style=for-the-badge)
![FAISS](https://img.shields.io/badge/Vector%20Search-FAISS-green?style=for-the-badge)
![Status](https://img.shields.io/badge/Status-Active-success?style=for-the-badge)

---

## ğŸš€ Live Demo  
ğŸ”— **Temporary Gradio Link (Colab):**  
`https://aa84b415606fb50cac.gradio.live/`

ğŸ”— **Hugging Face Spaces Demo:**  
*(Coming soon)*

---

## ğŸ§  Overview  
This chatbot answers questions grounded **directly from your documents** using a Retrieval-Augmented Generation (RAG) pipeline.

### It works in 3 steps:
1ï¸âƒ£ **Retrieve** â†’ Find relevant document chunks using FAISS  
2ï¸âƒ£ **Augment** â†’ Pass retrieved data into the model  
3ï¸âƒ£ **Generate** â†’ FLAN-T5 creates the final answer  

This reduces hallucination and ensures high accuracy.

---

## ğŸ—ï¸ Architecture  

Documents â†’ Chunking â†’ Embeddings (MiniLM) â†’ FAISS Vector Search â†’ FLAN-T5 â†’ Answer

yaml
Copy code

---

## ğŸ› ï¸ Tech Stack

### **Core Libraries**
- Hugging Face Transformers  
- Sentence Transformers  
- FAISS (Vector Search DB)  
- Gradio  
- PyTorch  

### **Models Used**
- **Embedding Model:** all-MiniLM-L6-v2  
- **Generator Model:** FLAN-T5-small  

---

## ğŸ“‚ Project Structure  

rag-document-chatbot/
â”‚
â”œâ”€â”€ app.py # Gradio chatbot UI
â”œâ”€â”€ ingest_index.py # Builds FAISS vector index
â”œâ”€â”€ requirements.txt # Dependencies
â”œâ”€â”€ README.md # Documentation
â”œâ”€â”€ meta.json # Chunk metadata (auto-generated)
â”œâ”€â”€ vector.index # FAISS index (auto-generated)
â”‚
â”œâ”€â”€ docs/ # Input documents
â”‚ â””â”€â”€ sample.txt
â”‚
â”œâ”€â”€ .gradio/ # Auto-created by Gradio
â””â”€â”€ pycache/ # Auto-created

yaml
Copy code

---

## â–¶ï¸ How to Run Locally

### **1ï¸âƒ£ Install dependencies**
```bash
pip install -r requirements.txt
2ï¸âƒ£ Add your documents
Place .txt or .md files inside:

Copy code
docs/
3ï¸âƒ£ Build FAISS index
bash
Copy code
python ingest_index.py --docs docs
This generates:

vector.index

meta.json

4ï¸âƒ£ Run the chatbot
bash
Copy code
python app.py
Open the Gradio link shown (example: http://localhost:7860)

ğŸ§ª Features
âœ” Uses your own documents
âœ” Fast vector search using FAISS
âœ” Context-grounded answers
âœ” Lightweight & easy to run
âœ” Beginner-friendly RAG pipeline

ğŸ”® Future Enhancements
PDF ingestion (pdfplumber)

Reranker for improved accuracy

Multi-document chat history

Mistral / Llama-3 upgrade

Hugging Face Spaces deployment

ğŸ‘¤ Author
Mohitha Papudesi
ğŸ”— GitHub: https://github.com/Mohitha1514
ğŸ”— LinkedIn: (https://www.linkedin.com/in/mohitha-papudesi)
